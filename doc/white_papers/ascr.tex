\documentclass[12pt]{article}

% RRL: I think "geometry" takes care of these more consistently.
% \textwidth=7in
% \textheight=9.5in
% \topmargin=-1in
% \headheight=0in
% \headsep=.5in
% \hoffset  -.85in

\usepackage{geometry}
\geometry{verbose,letterpaper,
  tmargin=0.5in,bmargin=1in,lmargin=1in,rmargin=1in,
  headheight=0in,headsep=0in,footskip=0.5in}

\usepackage{graphicx}
\usepackage{multirow}
\usepackage{setspace}
\usepackage{array}
\usepackage{hyperref}


\title{Exascale Ray Tracing: A White Paper}
\author{Ellen A. Porter\footnote{
    Battelle Pacific Northwest National Laboratory 
    and Washington State University;
    Program in Engineering and Computer Science
    (\texttt{ellen.porter@pnnl.gov})
  }
\hspace{1in} Robert R. Lewis\footnote{
    Washington State University;
    Program in Engineering and Computer Science
    (\texttt{bobl@tricity.wsu.edu})
  }
}

\frenchspacing

\pagestyle{empty}

\begin{document}
\maketitle

\section*{Introduction}

Exascale computers, being defined as being capable of performing at
least one exaflop (10$^{18}$ floating point operations per second),
are anticipated by 2018. This is three orders of magnitude greater
than current supercomputers.

Scaling applications to exascale is a task that will take significant
programming effort. Conclusions from several DOE-funded research
projects suggest that at exascale we will see a shift in programming
models away from traditional ``bulk synchronous'' (aka,
``machine-level'') parallel computing models, such as MPI (possibly
combined with OpenMP), and towards high level ``task-based''
programming models. In these, the mapping of execution to hardware is
based upon a developer-designated logical partitioning of the program
as opposed to, say, preassigned threads.

Task-based models rely more heavily on the runtime for optimization,
especially load balancing, and fault tolerance, which is expected to
be a fact of life on exascale computers. We are proposing to
investigate the implications of these models for ray tracing.

Ray tracing is a widely-used algorithm. Beyond its well-recognized
applications in entertainment, it has also been used to study radio
signal propagation, ocean acoustics, optical design, seismology,
plasma physics, and the design of nuclear facilities. Often, ray
tracing is used for data visualization. 
Manta (University of Utah) and pvOSPRay (Texas Advanced Computing
Center) are two ray tracing plugins developed for core HPC
visualization tools such as VisIt and ParaView.
Both of them work on distributed systems
but will not scale to exascale in their current form.

\section*{Proposed Work}

We propose the development of a generic task-based ray tracing system
that will run on both today's hardware and tomorrow's exascale
machines. As ray tracing in general is not a new field we will
implement a system that takes advantage of existing highly optimized
open source ray tracing engines. It may be integrated into a
visualization system or it may run as a stand-alone program.

\subsection*{Phase 1: Bulk Synchronous System}

We will first design and build a cluster that is capable of performing
bulk synchronous ray tracing. This may take the form of an implementation
of OSPRay

RESUME

We will integrate first with Intel's ray tracing library, Embree, this is the same kernel being used by pvOSPRay and has been optimized for several intel chips including Xeon Phi.  Future work may include integrating with OptiX, NVidia's ray tracing kernel to run on GPUs as well as extending the algorithm to dynamically choose at runtime which library or libraries to used based on the current runtime system.

\subsection*{Phase 2: Adapting to Task-Based Systems}

As with other applications, the shift towards exascale will take us towards task-based programming models and change the underlying hardware.  This has implications on ray tracing and is what we will explore in the second phase of our work.  For example, many existing distributed ray tracers work by duplicating input data across nodes.  As the size of memory per node is projected to decline significantly at exascale, this key design assumption will hinder current algorithms performance.  We will therefore redesign the current algorithms and implement a solution using Intel CnC, a task-based model, that will perform on today's architecture as well as next generation.  

\subsection*{Phase 3: Library Extensions}

With the base system in place we then plan to extend our work in two key ways; optimizing performance and increasing impact.  On many proposed task-based programming models, including CnC, a separate input file can be provided to the runtime to provide hints for scheduling and data movement to increase performance.  We would like to implement and test this tuning specification on different systems to determine the usefulness and necessity for ray tracing algorithms.  Finally we would like to extend our work towards more ray tracing functionality such as global illumination, support for multiple displays, and virtual reality headsets.

\section*{Conclusion}

We hope that with the coming of exascale, full ray tracing and full global illumination of large data sets will be efficient enough to be used for everyday data visualization.  Although we do not have exascale architectures available yet, we propose to produce a model that will work sufficiently at on today's distributed systems as well as future systems.

\end{document}